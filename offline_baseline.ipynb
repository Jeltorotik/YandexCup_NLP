{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "offline_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1Iis-3crv-zT"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "921c4b838c974d8380eeb0e504121d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_131181188e744b90adf054c029aa5611",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4dfe80bf9e7341c0bb7551fcd7585ddb",
              "IPY_MODEL_a80d5c4a8c3a4440b0111ba8a5e7146f",
              "IPY_MODEL_3a6d16a75b57444bbe7ccb2ad2277768"
            ]
          }
        },
        "131181188e744b90adf054c029aa5611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dfe80bf9e7341c0bb7551fcd7585ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_28d367e8cc904fb9a88123cc89f43796",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_36c49e615d824680a16fa3695787ee3f"
          }
        },
        "a80d5c4a8c3a4440b0111ba8a5e7146f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7841cd8bf7c8405b95077604f65d13d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b50768febbd94b1fb6c6655197956500"
          }
        },
        "3a6d16a75b57444bbe7ccb2ad2277768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_95ddfc609e764ce7a632c85681469616",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25/25 [00:10&lt;00:00,  2.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fcaad58467344d638cd0aa569a212311"
          }
        },
        "28d367e8cc904fb9a88123cc89f43796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "36c49e615d824680a16fa3695787ee3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7841cd8bf7c8405b95077604f65d13d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b50768febbd94b1fb6c6655197956500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "95ddfc609e764ce7a632c85681469616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fcaad58467344d638cd0aa569a212311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "511893a6dc3f4d699729ea5bcfa43559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d281df938e014aea9d6c4b4486dceba8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ab30ca21e3c43aabd88645a04b3f830",
              "IPY_MODEL_333fd633782f4d4ca28899a9b0321151",
              "IPY_MODEL_a88b11a45b254fe0a5c6da93e7ac5c9f"
            ]
          }
        },
        "d281df938e014aea9d6c4b4486dceba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ab30ca21e3c43aabd88645a04b3f830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_387a465eae864adea62ad321cce3f624",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_083c8acd549240d08259dd75833d6ac8"
          }
        },
        "333fd633782f4d4ca28899a9b0321151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c7614ec61b554aa4b9b90028fd1c4d4e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1627,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1627,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aea041ac6e454edc8fb3d78e312a7587"
          }
        },
        "a88b11a45b254fe0a5c6da93e7ac5c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91dfdfb126fa463d908b01b70237e676",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1627/1627.0 [01:14&lt;00:00, 22.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ee1c7ae1b2845d5b3ce872825dfa914"
          }
        },
        "387a465eae864adea62ad321cce3f624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "083c8acd549240d08259dd75833d6ac8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7614ec61b554aa4b9b90028fd1c4d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aea041ac6e454edc8fb3d78e312a7587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91dfdfb126fa463d908b01b70237e676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ee1c7ae1b2845d5b3ce872825dfa914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0414507da0f743b3a9a5c3f2f80e25a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c2ecb133c844a0ba5dd61bf8fa072d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12eb840b3b3e4d2d8163d86ae4a1910f",
              "IPY_MODEL_2886b777abf4447f8de5af186dff225a",
              "IPY_MODEL_a75a23be7511430fac2a56947078c4e2"
            ]
          }
        },
        "2c2ecb133c844a0ba5dd61bf8fa072d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12eb840b3b3e4d2d8163d86ae4a1910f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0d20e811ad64e7092284b15c5c8f28a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_125c049feb104f26a196c31962413cb1"
          }
        },
        "2886b777abf4447f8de5af186dff225a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a4befa61fc94badb40fb035fe73f52f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 305,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8003ebbe4beb4f93aa83ecb6565097a9"
          }
        },
        "a75a23be7511430fac2a56947078c4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_66209bfacb724787952ab10029e9a7e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 305/2500 [03:49&lt;21:37,  1.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_613ed5ae7f4c45c0801a2a2bdeb0874b"
          }
        },
        "f0d20e811ad64e7092284b15c5c8f28a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "125c049feb104f26a196c31962413cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a4befa61fc94badb40fb035fe73f52f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8003ebbe4beb4f93aa83ecb6565097a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66209bfacb724787952ab10029e9a7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "613ed5ae7f4c45c0801a2a2bdeb0874b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PPoi8vIqg3N",
        "outputId": "eefcfb77-ae98-42ed-bcfb-3b2b18cd84d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/YandexCup/\""
      ],
      "id": "4PPoi8vIqg3N",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j48XMiSVnQ5L"
      },
      "source": [
        "Загружаем скачанный классификатор токсичности:"
      ],
      "id": "j48XMiSVnQ5L"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trDj06qnJCnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86fd3af-b303-4874-8065-056d42fecfe7"
      },
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q natasha\n",
        "!pip install -q pymorphy2\n",
        "!pip install -q -U pymorphy2-dicts-ru\n",
        "!pip install -q hnswlib\n",
        "!pip install -q pymystem3\n",
        "!pip install -q pymorphy2\n",
        "!pip install -q -U pymorphy2-dicts-ru"
      ],
      "id": "trDj06qnJCnr",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9 MB 12.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 62.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 75.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 67.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 56 kB/s \n",
            "\u001b[K     |████████████████████████████████| 49 kB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 163 kB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 46.5 MB/s \n",
            "\u001b[?25h  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for hnswlib (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-t83-1unQ5T"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "  \n",
        "tokenizer = AutoTokenizer.from_pretrained(DRIVE_PATH + \"trained_roberta\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(DRIVE_PATH + \"trained_roberta\").cuda()\n",
        "\n",
        "TOXIC_CLASS=-1\n",
        "TOKENIZATION_TYPE='sentencepiece'\n"
      ],
      "id": "I-t83-1unQ5T",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9kNHI42nQ5Y"
      },
      "source": [
        "Ниже функции для применения классификатора"
      ],
      "id": "d9kNHI42nQ5Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WmnQL19nQ5Z"
      },
      "source": [
        "from torch import softmax, sigmoid\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import argparse\n",
        "from pymystem3 import Mystem\n",
        "import sys\n",
        "from collections import Counter\n",
        "from functools import partial\n",
        "\n",
        "\n",
        "\n",
        "ALLOWED_ALPHABET=list(map(chr, range(ord('а'), ord('я') + 1)))\n",
        "ALLOWED_ALPHABET.extend(map(chr, range(ord('a'), ord('z') + 1)))\n",
        "ALLOWED_ALPHABET.extend(list(map(str.upper, ALLOWED_ALPHABET)))\n",
        "ALLOWED_ALPHABET = set(ALLOWED_ALPHABET)\n",
        "\n",
        "\n",
        "def logits_to_toxic_probas(logits):\n",
        "    if logits.shape[-1] > 1:\n",
        "        activation = lambda x: softmax(x, -1)\n",
        "    else:\n",
        "        activation = sigmoid\n",
        "    return activation(logits)[:, TOXIC_CLASS].cpu().detach().numpy()\n",
        "\n",
        "\n",
        "def is_word_start(token):\n",
        "    if TOKENIZATION_TYPE == 'sentencepiece':\n",
        "        return token.startswith('▁')\n",
        "    if TOKENIZATION_TYPE == 'bert':\n",
        "        return not token.startswith('##')\n",
        "    raise ValueError(\"Unknown tokenization type\")\n",
        "\n",
        "\n",
        "def normalize(sentence, max_tokens_per_word=20):\n",
        "    sentence = ''.join(map(lambda c: c if c.isalpha() else ' ', sentence.lower()))\n",
        "    ids = tokenizer(sentence)['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(ids)[1:-1]\n",
        "    \n",
        "    result = []\n",
        "    num_continuation_tokens = 0\n",
        "    for token in tokens:\n",
        "        if not is_word_start(token):\n",
        "            num_continuation_tokens += 1\n",
        "            if num_continuation_tokens < max_tokens_per_word:\n",
        "                result.append(token.lstrip('#▁'))\n",
        "        else:\n",
        "            num_continuation_tokens = 0\n",
        "            result.extend([' ', token.lstrip('▁#')])\n",
        "    \n",
        "    return ''.join(result).strip()\n",
        "\n",
        "def iterate_batches(data, batch_size=40):\n",
        "    batch = []\n",
        "    for x in data:\n",
        "        batch.append(x)\n",
        "        if len(batch) >= batch_size:\n",
        "            yield batch\n",
        "            batch = []\n",
        "    if len(batch) > 0:\n",
        "        yield batch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "def predict_toxicity(sentences, batch_size=5, threshold=0.5, return_scores=False, verbose=True, device='cuda', off_tqdm=False):\n",
        "    results = []\n",
        "    tqdm_fn = tqdm if verbose else lambda x, total: x\n",
        "    for batch in tqdm_fn(iterate_batches(sentences, batch_size), total=np.ceil(len(sentences) / batch_size),  disable=off_tqdm):\n",
        "        normlized = [normalize(sent, max_tokens_per_word=5) for sent in batch]\n",
        "        tokenized = tokenizer(normlized, return_tensors='pt', padding=True, max_length=512, truncation=True)\n",
        "        \n",
        "        model_input = {key: val.to(device) for key, val in tokenized.items()}\n",
        "        \n",
        "        logits = model.to(device)(**model_input).logits\n",
        "        \n",
        "        preds = logits_to_toxic_probas(logits)\n",
        "        \n",
        "        if not return_scores:\n",
        "            preds = preds >= threshold\n",
        "        results.extend(preds)\n",
        "    return results\n"
      ],
      "id": "7WmnQL19nQ5Z",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cNawjDcnQ5c"
      },
      "source": [
        "Читаем тестовый набор"
      ],
      "id": "-cNawjDcnQ5c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BVH1K8pnQ5d",
        "outputId": "79413bbd-9404-40e2-ccbd-02549baed8a8"
      },
      "source": [
        "texts = []\n",
        "raw_texts = []\n",
        "with open(DRIVE_PATH + 'public_testset.txt', 'rt') as f:\n",
        "    for line in f:\n",
        "        raw_texts.append(line) \n",
        "        texts.append(normalize(line))"
      ],
      "id": "3BVH1K8pnQ5d",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-M9Ks4NnQ5e"
      },
      "source": [
        "Вычисляем токсичность отдельных слов"
      ],
      "id": "o-M9Ks4NnQ5e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFeGS8b5H44E"
      },
      "source": [
        "Посчитаем токсичность для каждого предложения:"
      ],
      "id": "tFeGS8b5H44E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "921c4b838c974d8380eeb0e504121d1a",
            "131181188e744b90adf054c029aa5611",
            "4dfe80bf9e7341c0bb7551fcd7585ddb",
            "a80d5c4a8c3a4440b0111ba8a5e7146f",
            "3a6d16a75b57444bbe7ccb2ad2277768",
            "28d367e8cc904fb9a88123cc89f43796",
            "36c49e615d824680a16fa3695787ee3f",
            "7841cd8bf7c8405b95077604f65d13d5",
            "b50768febbd94b1fb6c6655197956500",
            "95ddfc609e764ce7a632c85681469616",
            "fcaad58467344d638cd0aa569a212311"
          ]
        },
        "id": "dUV4MFFuH9z0",
        "outputId": "137a6ba6-0ef1-429e-f832-d470d57817d1"
      },
      "source": [
        "line_toxicities = []\n",
        "line_mean_toxicities = []\n",
        "\n",
        "for line in tqdm(np.random.choice(raw_texts, 25)):\n",
        "    pred = predict_toxicity([line], return_scores=True, off_tqdm=True)\n",
        "    \n",
        "    line_words = normalize(line).split()\n",
        "    toxi = [predict_toxicity([word], return_scores=True, off_tqdm=True) for word in line_words]\n",
        "    \n",
        "    line_toxicities.append(pred[0])\n",
        "    line_mean_toxicities.append(np.mean(toxi))\n",
        "\n"
      ],
      "id": "dUV4MFFuH9z0",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "921c4b838c974d8380eeb0e504121d1a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmP3tB70YW7K",
        "outputId": "51c61ca4-fb44-4f29-f2b6-dcccc3fa9d10"
      },
      "source": [
        "print(f\"На ({len(line_toxicities)} комментах):\")\n",
        "print(np.mean(line_toxicities), f\"- средняя токсичность всего комментария\")\n",
        "print(np.mean(line_mean_toxicities), \"- cредняя токсичность каждого слова в комментарии\")"
      ],
      "id": "PmP3tB70YW7K",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "На (25 комментах):\n",
            "0.5373261 - средняя токсичность всего комментария\n",
            "0.18996425 - cредняя токсичность каждого слова в комментарии\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_l4JOb1Sfo0d",
        "outputId": "9e1047a7-d847-4225-aed7-d75cf9868131"
      },
      "source": [
        "\n",
        "line = raw_texts[100]\n",
        "pred = predict_toxicity([line], return_scores=True, off_tqdm=True)\n",
        "\n",
        "line_words = normalize(line).split()\n",
        "toxi = [predict_toxicity([word], return_scores=True, off_tqdm=True) for word in line_words]\n",
        "\n",
        "print(line)\n",
        "print(pred)\n",
        "print(line_words)\n",
        "print(toxi)\n",
        "\n"
      ],
      "id": "_l4JOb1Sfo0d",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Можно сказать проще - кукуха едет от старческого маразма.\n",
            "\n",
            "[0.8303647]\n",
            "['можно', 'сказать', 'проще', 'кукуха', 'едет', 'от', 'старческого', 'маразма']\n",
            "[[0.07630243], [0.2619401], [0.04409236], [0.56395835], [0.15138271], [0.0645212], [0.2058756], [0.63614625]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8PZTCsgkoyh",
        "outputId": "68253a71-32bf-481d-f710-7dac1734852c"
      },
      "source": [
        "def sort_by_toxicity(words):\n",
        "    toxicities = predict_toxicity(words, return_scores = True, off_tqdm=True)\n",
        "    #[токсичность, индекс, слово]\n",
        "    result = [[toxicities[i], i, words[i]] for i in range(len(words))]\n",
        "    result.sort()\n",
        "    return result\n",
        "\n",
        "line = line = np.random.choice(raw_texts)\n",
        "pred = predict_toxicity([line], return_scores=True, off_tqdm=True)\n",
        "\n",
        "line_words = normalize(line).split()\n",
        "\n",
        "print(sort_by_toxicity(line_words))"
      ],
      "id": "h8PZTCsgkoyh",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.022175852, 0, 'респект'], [0.048265655, 4, 'вообще'], [0.05011496, 6, 'первую'], [0.061193287, 9, 'то'], [0.06933392, 1, 'эти'], [0.07038343, 10, 'ещё'], [0.082705215, 7, 'полосу'], [0.085665196, 5, 'на'], [0.09521889, 3, 'надо'], [0.18159607, 12, 'ставят'], [0.2817572, 8, 'а'], [0.4454826, 11, 'дизы'], [0.5695918, 14, 'людишки'], [0.8388674, 13, 'тупорые'], [0.98567885, 2, 'уродов']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eBW4a9SnQ5g"
      },
      "source": [
        "Ниже читаем эмбеддинги слов и описываем функции их обработки"
      ],
      "id": "7eBW4a9SnQ5g"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rGJ6ptQnQ5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf73820e-9b12-4fb4-e708-b0013aee7276"
      },
      "source": [
        "import gensim\n",
        "from pymystem3 import Mystem\n",
        "\n",
        "stemmer = Mystem()\n",
        "#lemmas = stemmer.lemmatize(\"Красивая мама красиво мыла раму\")"
      ],
      "id": "_rGJ6ptQnQ5h",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw6Cw6OrhQ_0"
      },
      "source": [
        "!pip install -q pymorphy2\n",
        "!pip install -q -U pymorphy2-dicts-ru\n",
        "\n",
        "from pymystem3 import Mystem\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import pymorphy2\n",
        "\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer(lang='ru')"
      ],
      "id": "Sw6Cw6OrhQ_0",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAHXRXFAnQ5h"
      },
      "source": [
        "embs_file = np.load(DRIVE_PATH + 'embeddings_with_lemmas.npz', allow_pickle=True)\n",
        "embs_vectors = embs_file['vectors']\n",
        "embs_vectors_normed = embs_vectors / np.linalg.norm(embs_vectors, axis=1, keepdims=True)\n",
        "embs_voc = embs_file['voc'].item()\n",
        "\n",
        "embs_voc_by_id = [None for i in range(len(embs_vectors))]\n",
        "for word, idx in embs_voc.items():\n",
        "    if embs_voc_by_id[idx] is None:\n",
        "        embs_voc_by_id[idx] = word"
      ],
      "id": "LAHXRXFAnQ5h",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "511893a6dc3f4d699729ea5bcfa43559",
            "d281df938e014aea9d6c4b4486dceba8",
            "2ab30ca21e3c43aabd88645a04b3f830",
            "333fd633782f4d4ca28899a9b0321151",
            "a88b11a45b254fe0a5c6da93e7ac5c9f",
            "387a465eae864adea62ad321cce3f624",
            "083c8acd549240d08259dd75833d6ac8",
            "c7614ec61b554aa4b9b90028fd1c4d4e",
            "aea041ac6e454edc8fb3d78e312a7587",
            "91dfdfb126fa463d908b01b70237e676",
            "5ee1c7ae1b2845d5b3ce872825dfa914"
          ]
        },
        "id": "eSk_dENb7N3g",
        "outputId": "f6fabdaa-206c-4a5f-ef80-50c1206ccbfe"
      },
      "source": [
        "words = set(embs_voc.keys())\n",
        "\n",
        "with torch.inference_mode():\n",
        "    word_toxicities = predict_toxicity(words, batch_size=100, return_scores=True)\n",
        "\n",
        "toxicity = dict(zip(words, word_toxicities))"
      ],
      "id": "eSk_dENb7N3g",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "511893a6dc3f4d699729ea5bcfa43559",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1627.0 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkdVwjmx4fFh",
        "outputId": "4b1698e3-3ca4-4c99-d062-67de97c27274"
      },
      "source": [
        "sorted_toxicity = {k: v for k, v in sorted(toxicity.items(), key=lambda item: item[1], reverse = True)}\n",
        "for k, v in list(sorted_toxicity.items())[:100]:\n",
        "    print(k ,v)"
      ],
      "id": "tkdVwjmx4fFh",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "благодаренута 0.9906294\n",
            "пиндостан 0.990629\n",
            "ублюдочный 0.9906288\n",
            "пиндосий 0.99062866\n",
            "долбоёб 0.9906279\n",
            "черноволосый 0.9906275\n",
            "ублюдок 0.9906267\n",
            "долбоёба 0.9906262\n",
            "пидораса 0.9906254\n",
            "долбоеба 0.99062496\n",
            "пиндосский 0.9906238\n",
            "черножопый 0.9906166\n",
            "пидорашка 0.99061453\n",
            "кондор 0.9906143\n",
            "пидорахо 0.9906136\n",
            "пиндос 0.9906108\n",
            "шаболовская 0.9906059\n",
            "пидорас 0.9906031\n",
            "уебищный 0.99060285\n",
            "ебанутый 0.9906\n",
            "андорра 0.99059266\n",
            "пидарас 0.99058306\n",
            "блюзовый 0.9905827\n",
            "ублюдка 0.99058\n",
            "выродок 0.99057066\n",
            "обернутый 0.99057007\n",
            "шабо 0.9905646\n",
            "пидарастка 0.9905353\n",
            "пидорский 0.99051744\n",
            "сувальдный 0.9905172\n",
            "выблядок 0.9905165\n",
            "пиндосия 0.9904979\n",
            "гейропа 0.9904908\n",
            "уебка 0.99048233\n",
            "пинбол 0.9904805\n",
            "черноголовка 0.99047625\n",
            "виталий::чуркин 0.990453\n",
            "швальба 0.99033934\n",
            "уебанский 0.99020326\n",
            "2ч::3п::4с::5в::6п::7в::8с::9ч::10п::11с::12в::13п::14в::15с::16ч::17п::18с::19в::20п::21в::22с::23ч::24п::25с::26в::27п::28в::29с::30ч 0.99019426\n",
            "чуркин 0.99019206\n",
            "пидараскать 0.9901198\n",
            "плечелопаточный 0.9900637\n",
            "выволочь 0.99004364\n",
            "пидараса 0.9899256\n",
            "педикулицидный 0.989813\n",
            "тнута 0.98951083\n",
            "кондолиза 0.98917854\n",
            "майданутый 0.9891672\n",
            "долбое 0.9891151\n",
            "шаболовский 0.98910344\n",
            "педераст 0.98890775\n",
            "черноголовый 0.98881453\n",
            "пиздолиз 0.98880565\n",
            "пендосий 0.98871887\n",
            "пидорашек 0.9886496\n",
            "1п::2с::3в::4п::5в::6с::7ч::8п::9с::10в::11п::12в::13с::14ч::15п::16с::17в::18п::19в::20с::21ч::22п::23с::24в::25п::26в::27с::28ч::29п::30с::31в 0.98860246\n",
            "ушлепок 0.98853916\n",
            "дечебал 0.9883465\n",
            "педикулезо 0.98823893\n",
            "педика 0.9882355\n",
            "выебал 0.98814386\n",
            "пидор 0.98812765\n",
            "tixati 0.9877051\n",
            "долбоеб 0.9877017\n",
            "ebitda 0.98764557\n",
            "азербайджан::гейдар::алиев 0.98758674\n",
            "исламевредоносный::бидъасловарь 0.987565\n",
            "кондолиза::райс 0.9875574\n",
            "дебила 0.987356\n",
            "быдлот 0.9872853\n",
            "оползнь 0.9870313\n",
            "гандбол::россия 0.986966\n",
            "недоумок 0.98695564\n",
            "вышивальный 0.98689646\n",
            "узбекистан::шавкат::мирзиёев 0.98663425\n",
            "ополченец 0.9865984\n",
            "гондон 0.98614883\n",
            "уебан 0.98561954\n",
            "жидкотопливный 0.9854489\n",
            "лиза::полыгалов 0.985305\n",
            "анальный 0.9850927\n",
            "прошмандовка 0.98440325\n",
            "шакро 0.9841643\n",
            "виталий::чуркина 0.98392063\n",
            "мудаки 0.98354095\n",
            "либерастовый 0.9834049\n",
            "тварный 0.9824814\n",
            "уебок 0.98190653\n",
            "хохляндия 0.98176944\n",
            "чуркина 0.9817516\n",
            "педалька 0.9816815\n",
            "пендоса 0.98159057\n",
            "дибила 0.9815834\n",
            "обосранный 0.9814944\n",
            "гейдаров 0.9811225\n",
            "piн 0.9811039\n",
            "пибодя 0.9806707\n",
            "гейроп 0.9803678\n",
            "аденоиды 0.9795568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Urk1iXpnQ5i"
      },
      "source": [
        "def get_w2v_indicies(a):\n",
        "    res = []\n",
        "    if isinstance(a, str):\n",
        "        a = a.split()\n",
        "    for w in a:\n",
        "        if w in embs_voc:\n",
        "            res.append(embs_voc[w])\n",
        "        else:\n",
        "            \n",
        "            lemma = morph.parse(w)[0].normal_form\n",
        "            res.append(embs_voc.get(lemma, None))\n",
        "    return res\n",
        "\n",
        "def calc_embs(words):\n",
        "    words = ' '.join(map(normalize, words))\n",
        "    inds = get_w2v_indicies(words)\n",
        "\n",
        "    return [None if i is None else embs_vectors[i] for i in inds]"
      ],
      "id": "0Urk1iXpnQ5i",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Dw297MnQ5i"
      },
      "source": [
        "Сложим эмбеддинги нетоксичных слов в kd-дерево, чтобы можно было близко искать ближайших соседей"
      ],
      "id": "M7Dw297MnQ5i"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4uoTUubxIA2",
        "outputId": "ca8e0264-728f-411a-ce22-c5dad52aef26"
      },
      "source": [
        "print(len(toxicity))"
      ],
      "id": "i4uoTUubxIA2",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK_b4NW_BKzS",
        "outputId": "f0acde96-a9cd-4949-b6df-72fc7313f272"
      },
      "source": [
        "MAX_TOXICITY  = 1\n",
        "\n",
        "non_toxicity = {word : val for word, val in toxicity.items() if val <= MAX_TOXICITY}\n",
        "\n",
        "nontoxic_emb_inds = [ind for word, ind in embs_voc.items() if toxicity.get(word, 1.0) <= MAX_TOXICITY]\n",
        "embs_vectors_normed_nontoxic = embs_vectors_normed[nontoxic_emb_inds]\n",
        "\n",
        "print(len(non_toxicity))"
      ],
      "id": "eK_b4NW_BKzS",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "162690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afLzttcHnQ5k"
      },
      "source": [
        "Функция находит самое близкое нетоксичное слово по предпосчитанным эмбеддингам слов"
      ],
      "id": "afLzttcHnQ5k"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f4StVNyvHe3",
        "outputId": "0b8d9cef-7ccf-4b18-b0a8-a1e4fb4d5842"
      },
      "source": [
        "embs_vectors_normed_nontoxic.shape"
      ],
      "id": "9f4StVNyvHe3",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162690, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnoIZVNXup7k"
      },
      "source": [
        "import hnswlib\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "num_elements, dim = embs_vectors_normed_nontoxic.shape\n",
        "\n",
        "# Generating sample data\n",
        "data = embs_vectors_normed_nontoxic\n",
        "ids = np.arange(num_elements)\n",
        "\n",
        "# Declaring index\n",
        "p = hnswlib.Index(space = 'cosine', dim = dim) # possible options are l2, cosine or ip\n",
        "\n",
        "# Initializing index - the maximum number of elements should be known beforehand\n",
        "p.init_index(max_elements = num_elements, ef_construction = 400, M = 16)\n",
        "\n",
        "# Element insertion (can be called several times):\n",
        "p.add_items(data, ids)"
      ],
      "id": "OnoIZVNXup7k",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snp_HC2OvYDp",
        "outputId": "f4bfb747-9d20-41f3-fbb4-55ce5f61fe94"
      },
      "source": [
        "word = \"идиот\"\n",
        "emb_word = calc_embs([word])\n",
        "for i in p.knn_query(emb_word, k = 15)[0][0]:\n",
        "    other_word = embs_voc_by_id[nontoxic_emb_inds[i]]\n",
        "    print(other_word, toxicity.get(other_word))"
      ],
      "id": "snp_HC2OvYDp",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "идиот 0.85655516\n",
            "дебил 0.97273284\n",
            "мудак 0.9194301\n",
            "идиота 0.8899699\n",
            "долбоеб 0.9877017\n",
            "идиотка 0.9372305\n",
            "долбоеба 0.99062496\n",
            "дурак 0.9634208\n",
            "дибил 0.9492958\n",
            "дурачок 0.8315148\n",
            "глупец 0.5484641\n",
            "долбое 0.9891151\n",
            "долбое 0.9891151\n",
            "кретин 0.8392081\n",
            "быдло 0.9608194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plv2lT94punc"
      },
      "source": [
        "#A better one\n",
        "\n",
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def find_closest_nontoxic(word, word_toxicity, allow_self=False):\n",
        "    #if toxicity.get(word, 1.0) <= threshold:\n",
        "    #    return word\n",
        "\n",
        "    #word_lemmatized = morph.parse(word)[0].normal_form\n",
        "    if word not in embs_voc:\n",
        "        #if word_lemmatized not in embs_voc:\n",
        "            return word_toxicity, word\n",
        "        #else:\n",
        "           # word = word_lemmatized\n",
        "    \n",
        "\n",
        "    #threshold = min(toxicity.get(word, threshold), threshold)\n",
        "    \n",
        "    word_emb = calc_embs([word])\n",
        "    if word_emb is None or word_emb[0] is None:\n",
        "        return word_toxicity, word\n",
        "\n",
        "\n",
        "    query = p.knn_query(word_emb, k = 200)[0][0]\n",
        "\n",
        "\n",
        "    best_candidate = word\n",
        "    best_score = word_toxicity\n",
        "\n",
        "    \n",
        "\n",
        "    for i in query:\n",
        "        candidate = embs_voc_by_id[nontoxic_emb_inds[i]]\n",
        "        similarity = distance_score(word, candidate)\n",
        "        \n",
        "        if (1 - toxicity.get(candidate)) + (similarity) > best_score:\n",
        "            \n",
        "            best_score = (1 - toxicity.get(candidate)) + (similarity)\n",
        "            best_candidate = candidate \n",
        "            \n",
        "    return toxicity.get(candidate), best_candidate\n"
      ],
      "id": "Plv2lT94punc",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftLSLtKPnQ5l"
      },
      "source": [
        "Заменяем токсичные слова на ближайшие по эмбеддингам не-токсичные"
      ],
      "id": "ftLSLtKPnQ5l"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwfKHeX9nQ5l"
      },
      "source": [
        "def detox(line):\n",
        "    \n",
        "    words = normalize(line).split()\n",
        "    sorted_words = sort_by_toxicity(words) #[токсичность, индекс, слово]\n",
        "    \n",
        "    \n",
        "    #cur_toxicity = predict_toxicity([' '.join(words)], return_scores=True, off_tqdm=True)[0]\n",
        "  \n",
        "    while sorted_words:\n",
        "        toxic_toxicity, toxic_idx, toxic_word = sorted_words.pop()\n",
        "        if toxic_toxicity > 0.77:\n",
        "            fixed_word = \"спасибо\"\n",
        "        else:\n",
        "            fixed_toxicity, fixed_word = find_closest_nontoxic(toxic_word, toxic_toxicity, allow_self = True)\n",
        "        words[toxic_idx] = fixed_word\n",
        "        #if fixed_word != toxic_word:\n",
        "        #    sorted_words.append([fixed_toxicity, toxic_idx, fixed_word])\n",
        "        #    sorted_words.sort()\n",
        "        \n",
        "        #cur_toxicity = predict_toxicity([' '.join(words)], return_scores=True, off_tqdm=True)[0]\n",
        "        \n",
        "\n",
        "    \n",
        "    return ' '.join(words)"
      ],
      "id": "uwfKHeX9nQ5l",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7-Z0tW8jnd-",
        "outputId": "9caf80f7-a908-44a6-ad9d-b8336c555b2a"
      },
      "source": [
        "len(nontoxic_emb_inds)"
      ],
      "id": "A7-Z0tW8jnd-",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162690"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "ca7abe64d19840c69ca637a4ad7cd3e1",
            "5f95ae2a94fe487796fc0149f526efbc"
          ]
        },
        "id": "fNPmaQ32CJLP",
        "outputId": "27ade61a-939e-4c8d-8dad-19e6a80f7657"
      },
      "source": [
        "Original = []\n",
        "Detoxed = []\n",
        "for i in tqdm(range(0, len(texts), 25)):\n",
        "    line = texts[i]\n",
        "    detoxed = detox(line)\n",
        "    Original.append(line)\n",
        "    Detoxed.append(detoxed)\n",
        "\n",
        "\n",
        "new_checker(Original, Detoxed)"
      ],
      "id": "fNPmaQ32CJLP",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca7abe64d19840c69ca637a4ad7cd3e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f95ae2a94fe487796fc0149f526efbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "average toxicity: 0.44503346\n",
            "mean lmdiff: 0.9199872424285057\n",
            "mean distance_score: 0.8360369109706309\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "43.749843042478545"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0414507da0f743b3a9a5c3f2f80e25a4",
            "2c2ecb133c844a0ba5dd61bf8fa072d1",
            "12eb840b3b3e4d2d8163d86ae4a1910f",
            "2886b777abf4447f8de5af186dff225a",
            "a75a23be7511430fac2a56947078c4e2",
            "f0d20e811ad64e7092284b15c5c8f28a",
            "125c049feb104f26a196c31962413cb1",
            "4a4befa61fc94badb40fb035fe73f52f",
            "8003ebbe4beb4f93aa83ecb6565097a9",
            "66209bfacb724787952ab10029e9a7e0",
            "613ed5ae7f4c45c0801a2a2bdeb0874b"
          ]
        },
        "id": "bkSTy4lhnQ5m",
        "outputId": "2b8019c8-da90-4453-815a-665da3cc6b76"
      },
      "source": [
        "fixed_texts = list(map(detox, tqdm(texts)))\n",
        "\n",
        "with open(DRIVE_PATH + 'submits/sorted_fixed.txt', 'wt') as f:\n",
        "    for text in fixed_texts:\n",
        "        print(text, file=f)\n",
        "\n",
        "new_checker(texts, fixed_texts)"
      ],
      "id": "bkSTy4lhnQ5m",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0414507da0f743b3a9a5c3f2f80e25a4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA4ZdcdtnQ5n"
      },
      "source": [
        "with open(DRIVE_PATH + 'submits/sorted_fixed.txt', 'wt') as f:\n",
        "    for text in fixed_texts:\n",
        "        print(text, file=f)"
      ],
      "id": "eA4ZdcdtnQ5n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RuRhakQwFHh"
      },
      "source": [
        "#Score"
      ],
      "id": "1RuRhakQwFHh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jjjQyE2wl7L",
        "outputId": "6102d261-b663-4ba1-8e40-6521ed0ea994"
      },
      "source": [
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install -q kenlm"
      ],
      "id": "9jjjQyE2wl7L",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Downloading https://github.com/kpu/kenlm/archive/master.zip\n",
            "\u001b[K     \\ 540 kB 5.5 MB/s\n",
            "\u001b[?25hBuilding wheels for collected packages: kenlm\n",
            "  Building wheel for kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kenlm: filename=kenlm-0.0.0-cp37-cp37m-linux_x86_64.whl size=2331827 sha256=45bb2a7e71e05bac49bbb48bcc5849e50ee1830404c3e4cc1679c0bb797b652b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8thpmg9t/wheels/3d/aa/02/7b4a2eab5d7a2a9391bd9680dbad6270808a147bc3b7047e4e\n",
            "Successfully built kenlm\n",
            "Installing collected packages: kenlm\n",
            "Successfully installed kenlm-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5SFllGhwHmz"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from torch import softmax, sigmoid\n",
        "from tqdm.auto import tqdm\n",
        "import argparse\n",
        "from pymystem3 import Mystem\n",
        "import sys\n",
        "from collections import Counter\n",
        "from functools import partial\n",
        "import kenlm\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/YandexCup/trained_roberta\")\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/YandexCup/trained_roberta\").cuda()\n",
        "\n",
        "lm = kenlm.Model('/content/drive/MyDrive/YandexCup/lm.binary')\n",
        "\n",
        "\n",
        "\n",
        "TOXIC_CLASS=-1\n",
        "TOKENIZATION_TYPE='sentencepiece'\n",
        "\n",
        "\n",
        "ALLOWED_ALPHABET=list(map(chr, range(ord('а'), ord('я') + 1)))\n",
        "ALLOWED_ALPHABET.extend(map(chr, range(ord('a'), ord('z') + 1)))\n",
        "ALLOWED_ALPHABET.extend(list(map(str.upper, ALLOWED_ALPHABET)))\n",
        "ALLOWED_ALPHABET = set(ALLOWED_ALPHABET)\n",
        "\n",
        "\n",
        "def logits_to_toxic_probas(logits):\n",
        "    if logits.shape[-1] > 1:\n",
        "        activation = lambda x: softmax(x, -1)\n",
        "    else:\n",
        "        activation = sigmoid\n",
        "    return activation(logits)[:, TOXIC_CLASS].cpu().detach().numpy()\n",
        "\n",
        "\n",
        "def is_word_start(token):\n",
        "    if TOKENIZATION_TYPE == 'sentencepiece':\n",
        "        return token.startswith('▁')\n",
        "    if TOKENIZATION_TYPE == 'bert':\n",
        "        return not token.startswith('##')\n",
        "    raise ValueError(\"Unknown tokenization type\")\n",
        "\n",
        "\n",
        "def normalize(sentence, max_tokens_per_word=20):\n",
        "    def validate_char(c):\n",
        "        return c in ALLOWED_ALPHABET\n",
        "    \n",
        "    sentence = ''.join(map(lambda c: c if validate_char(c) else ' ', sentence.lower()))\n",
        "    ids = tokenizer(sentence)['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(ids)[1:-1]\n",
        "    \n",
        "    result = []\n",
        "    num_continuation_tokens = 0\n",
        "    for token in tokens:\n",
        "        if not is_word_start(token):\n",
        "            num_continuation_tokens += 1\n",
        "            if num_continuation_tokens < max_tokens_per_word:\n",
        "                result.append(token.lstrip('#▁'))\n",
        "        else:\n",
        "            num_continuation_tokens = 0\n",
        "            result.extend([' ', token.lstrip('▁#')])\n",
        "    \n",
        "    return ''.join(result).strip()\n",
        "\n",
        "\n",
        "def iterate_batches(data, batch_size=40):\n",
        "    batch = []\n",
        "    for x in data:\n",
        "        batch.append(x)\n",
        "        if len(batch) >= batch_size:\n",
        "            yield batch\n",
        "            batch = []\n",
        "    if len(batch) > 0:\n",
        "        yield batch\n",
        "\n",
        "\n",
        "def predict_toxicity_1(sentences, batch_size=5, threshold=0.5, return_scores=False, verbose=True, device='cuda'):\n",
        "    results = []\n",
        "    for batch in iterate_batches(sentences, batch_size):\n",
        "        normlized = [normalize(sent, max_tokens_per_word=5) for sent in batch]\n",
        "        tokenized = tokenizer(normlized, return_tensors='pt', padding=True, max_length=512, truncation=True)\n",
        "    \n",
        "        logits = model.to(device)(**{key: val.to(device) for key, val in tokenized.items()}).logits\n",
        "        preds = logits_to_toxic_probas(logits)\n",
        "        if not return_scores:\n",
        "            preds = preds >= threshold\n",
        "        results.extend(preds)\n",
        "    return results\n",
        "\n",
        "\n",
        "def get_w2v_indicies_1(a):\n",
        "    res = []\n",
        "    if isinstance(a, str):\n",
        "        a = a.split()\n",
        "    for w in a:\n",
        "        if w in embs_voc:\n",
        "            res.append((w, embs_voc[w]))\n",
        "        else:\n",
        "            if w.isalpha():\n",
        "                lemma = morph.parse(w)[0].normal_form\n",
        "                res.append((embs_voc.get(lemma), None))\n",
        "    return res\n",
        "\n",
        "\n",
        "def load_embeddings(path):\n",
        "    embs_file = np.load(path, allow_pickle=True)\n",
        "    embs_vectors = embs_file['vectors']\n",
        "    embs_voc = embs_file['voc'].item()\n",
        "\n",
        "    embs_voc_by_id = [None for i in range(len(embs_vectors))]\n",
        "    for word, idx in embs_voc.items():\n",
        "        if embs_voc_by_id[idx] is None:\n",
        "            embs_voc_by_id[idx] = word\n",
        "    return embs_vectors, embs_voc, embs_voc_by_id\n",
        "\n",
        "\n",
        "def calc_embs_1(words):\n",
        "    words = ' '.join(map(normalize, words))\n",
        "    inds = get_w2v_indicies_1(words)\n",
        "    return [(w, i if i is None else embs_vectors[i]) for w, i in inds]\n",
        "\n",
        "\n",
        "def calc_single_embedding_dist(a, b):\n",
        "    a_s, a_v = a  #слово, вектор\n",
        "    b_s, b_v = b  #слово, вектор\n",
        "    if a_s == b_s: #если слова равны\n",
        "        return 0.0\n",
        "    if a_v is None or b_v is None: #если одно из векторов нет - дать пизды \n",
        "        return 1.0\n",
        "    a = a_v\n",
        "    b = b_v\n",
        "    # inexact match is punished by 0.1\n",
        "    return 0.1 + 0.9 * (1 - a.dot(b) / np.linalg.norm(a) / np.linalg.norm(b)) / 2\n",
        "\n",
        "\n",
        "def greedy_match_embs(a, b, max_dist=99999, cache=None, a_ind=0, b_ind=0):\n",
        "    a_len = len(a) - a_ind #сколько слов мы еще не рассмотрели в а\n",
        "    b_len = len(b) - b_ind #сколько слов мы еще не рассмотрели в b\n",
        "    minlen = min(a_len, b_len) #минимальная длина строки\n",
        "    maxlen = max(a_len, b_len) #минимальная длина строки\n",
        "    if minlen == 0: \n",
        "        return np.minimum(maxlen, max_dist) \n",
        "    if maxlen - minlen >= max_dist: \n",
        "        return max_dist \n",
        "    \n",
        "    if cache is None:\n",
        "        cache = {}\n",
        "    \n",
        "    cache_key = (a_len, b_len)\n",
        "    if cache_key in cache:\n",
        "        return cache[cache_key]\n",
        "        \n",
        "    min_dist = max_dist\n",
        "    \n",
        "    first_dist = calc_single_embedding_dist(a[a_ind], b[b_ind])\n",
        "    if max_dist >= first_dist:\n",
        "        min_dist = np.minimum(min_dist, first_dist + greedy_match_embs(\n",
        "            a, b, max_dist, cache, a_ind + 1, b_ind + 1\n",
        "        ))\n",
        "    \n",
        "    if first_dist > 0 and max_dist >= 1:\n",
        "        min_dist = np.minimum(min_dist, 1 + greedy_match_embs(\n",
        "            a, b, max_dist, cache, a_ind + 1, b_ind\n",
        "        ))\n",
        "        min_dist = np.minimum(min_dist, 1 + greedy_match_embs(\n",
        "            a, b, max_dist, cache, a_ind, b_ind + 1\n",
        "        ))\n",
        "    \n",
        "    cache[cache_key] = min_dist\n",
        "    \n",
        "    return min_dist\n",
        "\n",
        "\n",
        "\n",
        "def calc_semantic_distance(a, b):\n",
        "    a_embs = calc_embs_1(a)\n",
        "    b_embs = calc_embs_1(b)\n",
        "    \n",
        "    clip_distance = 5  # this clips long computations\n",
        "    return np.exp(-(greedy_match_embs(a_embs, b_embs, max_dist=clip_distance) / (0.6 * np.log(1 + len(a)))) ** 2)\n",
        "\n",
        "\n",
        "def distance_score(original, fixed):\n",
        "    original = original.split()\n",
        "    fixed = fixed.split()\n",
        "    \n",
        "    return calc_semantic_distance(original, fixed)\n",
        "\n",
        "\n",
        "def compute_lmdiff(original, fixed):\n",
        "    original_lm_logproba = lm.score(original, bos=True, eos=True)\n",
        "    fixed_lm_logproba = lm.score(fixed, bos=True, eos=True)\n",
        "    \n",
        "    probability_fraction = 10**((fixed_lm_logproba - original_lm_logproba) / 25)\n",
        "    \n",
        "    return np.clip(probability_fraction, 0.0, 1.0)\n",
        "\n",
        "\n",
        "def compute_score(original_sentences, fixed_sentences, threshold=0.5, batch_size=5):\n",
        "    fixed_toxicities = predict_toxicity_1(fixed_sentences, threshold=threshold, batch_size=batch_size, return_scores=True)\n",
        "    scores = []\n",
        "    lmdiffs = []\n",
        "    emb_dists = []\n",
        "    for original_sentence, fixed_sentence, fixed_toxicity in tqdm(zip(\n",
        "        original_sentences, fixed_sentences, fixed_toxicities\n",
        "    ), miniters=250):\n",
        "        original_sentence = normalize(original_sentence)\n",
        "        fixed_sentence = normalize(fixed_sentence)\n",
        "        \n",
        "        distance = distance_score(original_sentence, fixed_sentence)\n",
        "        lmdiff = compute_lmdiff(original_sentence, fixed_sentence)\n",
        "        \n",
        "        score = (1 - fixed_toxicity) * distance * lmdiff\n",
        "        \n",
        "        lmdiffs.append(lmdiff)\n",
        "        emb_dists.append(distance)\n",
        "        scores.append(score)\n",
        "    \n",
        "    print('average toxicity:', np.mean(fixed_toxicities), file=sys.stderr)\n",
        "    print('mean lmdiff:', np.mean(lmdiffs), file=sys.stderr)\n",
        "    print('mean distance_score:', np.mean(emb_dists), file=sys.stderr)\n",
        "    \n",
        "    return np.mean(scores)\n",
        "\n",
        "'''\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('original_texts', type=argparse.FileType('r'))\n",
        "    parser.add_argument('fixed_texts', type=argparse.FileType('r'))\n",
        "    parser.add_argument('--score', type=argparse.FileType('w'))\n",
        "    parser.add_argument('--model', required=True, type=str)\n",
        "    parser.add_argument('--embeddings', type=str, required=True)\n",
        "    parser.add_argument('--lm', type=str, required=True)\n",
        "    parser.add_argument('--device', type=str, choices=['cuda', 'cpu'], default='cpu')\n",
        "    \n",
        "    return parser.parse_args()\n",
        "'''\n",
        "\n",
        "def new_checker(original_texts, fixed_texts, device='cuda'):\n",
        "    original_texts = list(map(str.strip, original_texts))\n",
        "    fixed_texts = list(map(str.strip, fixed_texts))\n",
        "    \n",
        "    assert len(original_texts) == len(fixed_texts)\n",
        "    \n",
        "    with torch.inference_mode(True):\n",
        "        return (100 * compute_score(original_texts, fixed_texts))"
      ],
      "id": "V5SFllGhwHmz",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3ReNVfgxAzv"
      },
      "source": [
        "original_texts = []\n",
        "\n",
        "with open(DRIVE_PATH + 'public_testset.txt', 'rt') as f:\n",
        "    for line in f:\n",
        "        original_texts.append(normalize(line))\n",
        "\n",
        "text_for_eval = []\n",
        "with open(DRIVE_PATH + 'submits/sorted_fixed.txt', 'rt') as f:\n",
        "    for line in f:\n",
        "        text_for_eval.append(normalize(line))\n",
        "\n",
        "\n",
        "new_checker(original_texts, text_for_eval)"
      ],
      "id": "d3ReNVfgxAzv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaeTPVTznQ5n"
      },
      "source": [
        "Скор, если никак не изменять комментарии:"
      ],
      "id": "ZaeTPVTznQ5n"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUECywWdnQ5n"
      },
      "source": [
        "!python3.7 score.py public_testset.short.txt public_testset.short.txt  --embeddings embeddings_with_lemmas.npz --lm lm.binary --model ./trained_roberta/ --device cuda --score -"
      ],
      "id": "zUECywWdnQ5n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zllBqVOZnQ5o"
      },
      "source": [
        "Скор бейзлайна:"
      ],
      "id": "zllBqVOZnQ5o"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQngkQdLnQ5o"
      },
      "source": [
        "!python3.7 score.py public_testset.short.txt baseline_fixed.txt  --embeddings embeddings_with_lemmas.npz --lm lm.binary --model ./trained_roberta/ --device cuda --score -"
      ],
      "id": "pQngkQdLnQ5o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wtXSZn0nQ5p"
      },
      "source": [
        "Сохраним данные для бейзлайна online-задачи"
      ],
      "id": "7wtXSZn0nQ5p"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Iis-3crv-zT"
      },
      "source": [
        "##Для Online-решения"
      ],
      "id": "1Iis-3crv-zT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-OmT57snQ5p"
      },
      "source": [
        "!mkdir -p online_baseline"
      ],
      "id": "R-OmT57snQ5p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrI00hyYnQ5p"
      },
      "source": [
        "import pickle as pkl\n",
        "\n",
        "with open('./online_baseline/data.pkl', 'wb') as f:\n",
        "    pkl.dump(toxicity, f)\n",
        "    pkl.dump(nontoxic_emb_inds, f)"
      ],
      "id": "FrI00hyYnQ5p",
      "execution_count": null,
      "outputs": []
    }
  ]
}